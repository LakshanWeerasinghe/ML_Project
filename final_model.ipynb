{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ec30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# preprocessing imports\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder, OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea2be0",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3f80bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_parser(df):\n",
    "    date_recorder = list(map(lambda x: datetime.datetime.strptime(str(x), '%Y-%m-%d'),\n",
    "                             df['date_recorded'].values))\n",
    "    df['year_recorder'] = list(map(lambda x: int(x.strftime('%Y')), date_recorder))\n",
    "    df['yearly_week_recorder'] = list(map(lambda x: int(x.strftime('%W')), date_recorder))\n",
    "    df['month_recorder'] = list(map(lambda x: int(x.strftime('%m')), date_recorder))\n",
    "    df['age'] = df['year_recorder'].values - df['construction_year'].values\n",
    "    del df['date_recorded']\n",
    "    return df\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    mi_scores = mutual_info_classif(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI_SCORES\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def target_encode_multiclass(X_train, y, X_test, target_encoded_cols):\n",
    "    \n",
    "    y=y.astype(str)\n",
    "    \n",
    "    enc=ce.OneHotEncoder().fit(y)\n",
    "    y_onehot=enc.transform(y)\n",
    "    class_names=y_onehot.columns \n",
    "    \n",
    "    X_obj=X_train.select_dtypes('object') \n",
    "    X_train=X_train.select_dtypes(exclude='object')\n",
    "    \n",
    "    X_test_obj=X_test.select_dtypes('object')\n",
    "    X_test=X_test.select_dtypes(exclude='object')\n",
    "    \n",
    "    for class_ in class_names:\n",
    "        enc=ce.TargetEncoder()\n",
    "        enc.fit(X_obj,y_onehot[class_]) \n",
    "        \n",
    "        X_train_temp=enc.transform(X_obj)       \n",
    "        X_train_temp.columns=[str(x)+'_'+str(class_) for x in X_train_temp.columns]\n",
    "        \n",
    "        X_test_temp=enc.transform(X_test_obj)      \n",
    "        X_test_temp.columns=X_train_temp.columns\n",
    "        \n",
    "        target_encoded_cols.extend(list(X_train_temp.columns))\n",
    "        X_train=pd.concat([X_train, X_train_temp],axis=1)    \n",
    "        X_test=pd.concat([X_test, X_test_temp],axis=1)    \n",
    "      \n",
    "    return X_train, X_test, target_encoded_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f714b6",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436f497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "training_features_df = pd.read_csv('dataset/training_features.csv', index_col='id')\n",
    "training_labels_df = pd.read_csv('dataset/training_labels.csv', index_col='id')\n",
    "\n",
    "# testing data\n",
    "testing_features_df = pd.read_csv('dataset/test_features.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a5d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_group_mappings = {'functional': 1, 'non functional':2, 'functional needs repair': 3}\n",
    "training_labels_df['status_group'] = training_labels_df['status_group'].map(status_group_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44088e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_features_df, \n",
    "                                                    training_labels_df,\n",
    "                                                    test_size=0.3, random_state=42)\n",
    "datasets = [X_train, X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4fd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features_df = training_features_df.join(training_labels_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589370a",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62bb65",
   "metadata": {},
   "source": [
    "### 1. create new features using `date_recorded` and `construction_year`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2925674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset = date_parser(dataset)\n",
    "\n",
    "training_features_df = date_parser(training_features_df)\n",
    "testing_features_df = date_parser(testing_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05f19801",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [ 'amount_tsh',\n",
    "                 'gps_height',\n",
    "                 'longitude', \n",
    "                 'latitude',\n",
    "                 'region_code',\n",
    "                 'district_code',\n",
    "                 'population',\n",
    "                 'yearly_week_recorder',\n",
    "                 'month_recorder',\n",
    "                 'age'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d5b12",
   "metadata": {},
   "source": [
    "### 2. numeric features are scaled and imputed with `mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a54a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing features\n",
    "for col in numeric_cols:\n",
    "    scaler = StandardScaler()\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    \n",
    "    sclaer = scaler.fit(X_train[[col]])\n",
    "    for dataset in datasets:\n",
    "        dataset[col] = scaler.transform(dataset[[col]]).ravel()\n",
    "                \n",
    "    imputer= imputer.fit(X_train[[col]])\n",
    "    for dataset in datasets:\n",
    "        dataset[col] = imputer.transform(dataset[[col]]).ravel()\n",
    "\n",
    "# submission features\n",
    "for col in numeric_cols:\n",
    "    scaler = StandardScaler()\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    \n",
    "    sclaer = scaler.fit(training_features_df[[col]])\n",
    "    training_features_df[col] = scaler.transform(training_features_df[[col]]).ravel()\n",
    "    testing_features_df[col]  = scaler.transform(testing_features_df[[col]]).ravel()\n",
    "                \n",
    "    imputer= imputer.fit(training_features_df[[col]])\n",
    "    training_features_df[col] = scaler.transform(training_features_df[[col]]).ravel()\n",
    "    testing_features_df[col]  = scaler.transform(testing_features_df[[col]]).ravel()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f50db52",
   "metadata": {},
   "source": [
    "### 3. create a new feature `distance` using `latitude` and `longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed68aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing features\n",
    "X_train['distance'] = (X_train.latitude**2 + X_train.longitude**2)**0.5\n",
    "X_test['distance'] = (X_test.latitude**2 + X_test.longitude**2)**0.5\n",
    "\n",
    "# submission features \n",
    "training_features_df['distance'] = (training_features_df.latitude**2 + training_features_df.longitude**2)**0.5\n",
    "testing_features_df['distance'] = (testing_features_df.latitude**2 + testing_features_df.longitude**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76523b",
   "metadata": {},
   "source": [
    "### 4. create a new feature `angle` using `latitude` and `longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "168cca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing features\n",
    "X_train[\"angle\"] = np.arctan(X_train[\"latitude\"]/X_train[\"longitude\"])\n",
    "X_test[\"angle\"] = np.arctan(X_test[\"latitude\"]/X_test[\"longitude\"])\n",
    "\n",
    "\n",
    "training_features_df[\"angle\"] = np.arctan(training_features_df[\"latitude\"]/training_features_df[\"longitude\"])\n",
    "testing_features_df[\"angle\"] = np.arctan(testing_features_df[\"latitude\"]/testing_features_df[\"longitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4788ef",
   "metadata": {},
   "source": [
    "### 5. PCA for `latitude` and `longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2363093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing features\n",
    "pca = PCA().fit(X_train[['latitude', 'longitude']])\n",
    "X_train['distance_pca0'] = pca.transform(X_train[['latitude', 'longitude']])[:, 0]\n",
    "X_train['distance_pca1'] = pca.transform(X_train[['latitude', 'longitude']])[:, 1]\n",
    "X_test['distance_pca0'] = pca.transform(X_test[['latitude', 'longitude']])[:, 0]\n",
    "X_test['distance_pca1'] = pca.transform(X_test[['latitude', 'longitude']])[:, 1]\n",
    "\n",
    "pca1 = PCA().fit(training_features_df[['latitude', 'longitude']])\n",
    "training_features_df['distance_pca0'] = pca1.transform(training_features_df[['latitude', 'longitude']])[:, 0]\n",
    "training_features_df['distance_pca1'] = pca1.transform(training_features_df[['latitude', 'longitude']])[:, 1]\n",
    "testing_features_df['distance_pca0'] = pca1.transform(testing_features_df[['latitude', 'longitude']])[:, 0]\n",
    "testing_features_df['distance_pca1'] = pca1.transform(testing_features_df[['latitude', 'longitude']])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34720bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = ['distance', 'distance_pca0', 'distance_pca1', 'angle' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a23268fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_ohe = ['quantity','management_group','source_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24785662",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_after_cols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e12d41",
   "metadata": {},
   "source": [
    "### 6. categorical features used to ohe are imputed with `mode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c21cc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing features\n",
    "for col in cols_to_ohe:\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "            \n",
    "    imputer= imputer.fit(X_train[[col]])\n",
    "    for dataset in datasets:\n",
    "        dataset[col] = imputer.transform(dataset[[col]]).ravel()\n",
    "\n",
    "# submission features\n",
    "for col in cols_to_ohe:\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "            \n",
    "    imputer= imputer.fit(training_features_df[[col]])\n",
    "    training_features_df[col] = imputer.transform(training_features_df[[col]]).ravel()\n",
    "    testing_features_df[col]  = imputer.transform(testing_features_df[[col]]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72d5664",
   "metadata": {},
   "source": [
    "### 7. ohe categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3bfa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing features\n",
    "ohe =OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        \n",
    "train_cols = pd.DataFrame(ohe.fit_transform(X_train[cols_to_ohe]))\n",
    "test_cols = pd.DataFrame(ohe.transform(X_test[cols_to_ohe]))\n",
    "\n",
    "ohe_after_cols = train_cols.columns.values\n",
    "\n",
    "train_cols.index = X_train.index\n",
    "test_cols.index = X_test.index\n",
    "    \n",
    "X_train = X_train.drop(cols_to_ohe, axis=1)\n",
    "X_test = X_test.drop(cols_to_ohe, axis=1)\n",
    "    \n",
    "X_train = pd.concat([X_train, train_cols], axis=1)\n",
    "X_test = pd.concat([X_test, test_cols], axis=1)\n",
    "\n",
    "# submission features\n",
    "ohe =OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        \n",
    "train_cols = pd.DataFrame(ohe.fit_transform(training_features_df[cols_to_ohe]))\n",
    "test_cols = pd.DataFrame(ohe.transform(testing_features_df[cols_to_ohe]))\n",
    "\n",
    "ohe_after_cols = train_cols.columns.values\n",
    "\n",
    "train_cols.index = training_features_df.index\n",
    "test_cols.index = testing_features_df.index\n",
    "    \n",
    "training_features_df = training_features_df.drop(cols_to_ohe, axis=1)\n",
    "testing_features_df = testing_features_df.drop(cols_to_ohe, axis=1)\n",
    "    \n",
    "training_features_df = pd.concat([training_features_df, train_cols], axis=1)\n",
    "testing_features_df = pd.concat([testing_features_df, test_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e62f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_columns = [ 'basin',  \n",
    "                   'payment',\n",
    "                   'payment_type',\n",
    "                   'permit', \n",
    "                   'quantity_group',\n",
    "                   'water_quality',\n",
    "                   'quality_group',\n",
    "                   'region', \n",
    "                   'extraction_type_group', \n",
    "                   'extraction_type',\n",
    "                   'source',\n",
    "                   'source_type',\n",
    "                   'waterpoint_type',\n",
    "                   'waterpoint_type_group',\n",
    "                   'scheme_management',\n",
    "                   'subvillage',\n",
    "                   'ward',\n",
    "                   'wpt_name'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74074d3",
   "metadata": {},
   "source": [
    "### 8. categorical features used to ordinal are imputed with `mode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb10e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing features\n",
    "for col in ordinal_columns:\n",
    "    mode = X_train[col].mode()[0]\n",
    "    X_test[col] = X_test[col].fillna(mode)\n",
    "    X_train[col] = X_train[col].fillna(mode)\n",
    "\n",
    "# submission features\n",
    "for col in ordinal_columns:\n",
    "    mode = X_train[col].mode()[0]\n",
    "    training_features_df[col] = training_features_df[col].fillna(mode)\n",
    "    testing_features_df[col] = testing_features_df[col].fillna(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e8be61",
   "metadata": {},
   "source": [
    "### 9. ordinal categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d939d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing features\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='ignore')\n",
    "X_train[ordinal_columns] = ordinal_encoder.fit_transform(X_train[ordinal_columns])\n",
    "X_test[ordinal_columns] = ordinal_encoder.transform(X_test[ordinal_columns])\n",
    "\n",
    "# submission features\n",
    "final_ordinal_encoder = OrdinalEncoder(handle_unknown='ignore')\n",
    "training_features_df[ordinal_columns] = final_ordinal_encoder.fit_transform(training_features_df[ordinal_columns])\n",
    "testing_features_df[ordinal_columns] = final_ordinal_encoder.transform(testing_features_df[ordinal_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33f0e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_target_encoded_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a7bb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder_columns = ['lga', 'installer', 'funder','extraction_type_class', 'management']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d83e93",
   "metadata": {},
   "source": [
    "### 10. categorical features used to target encode are imputed with `constant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e82dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing features\n",
    "for col in target_encoder_columns:\n",
    "    X_test[col] = X_test[col].fillna('missing_value')\n",
    "    X_train[col] = X_train[col].fillna('missing_value')\n",
    "\n",
    "# submission features\n",
    "for col in target_encoder_columns:\n",
    "    training_features_df[col] = training_features_df[col].fillna('missing_value')\n",
    "    testing_features_df[col] = testing_features_df[col].fillna('missing_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c5fe1",
   "metadata": {},
   "source": [
    "### 11. Target Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8bb3924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "# training and testing features\n",
    "X_tar_train, X_tar_test, final_target_encoded_cols = target_encode_multiclass(X_train[target_encoder_columns], \n",
    "                                                   y_train.status_group, \n",
    "                                                   X_test[target_encoder_columns],\n",
    "                                                   final_target_encoded_cols)\n",
    "\n",
    "X_train = pd.concat([X_train, X_tar_train], axis=1)\n",
    "X_test = pd.concat([X_test, X_tar_test], axis=1)\n",
    "\n",
    "X_train = X_train.drop(target_encoder_columns, axis=1)\n",
    "X_test = X_test.drop(target_encoder_columns, axis=1)\n",
    "\n",
    "# submission features\n",
    "full_dataset_encoded_columns = []\n",
    "\n",
    "X_tar_train, X_tar_test, full_dataset_encoded_columns = target_encode_multiclass(\n",
    "                                                   training_features_df[target_encoder_columns], \n",
    "                                                   training_labels_df.status_group, \n",
    "                                                   testing_features_df[target_encoder_columns],\n",
    "                                                   full_dataset_encoded_columns)\n",
    "\n",
    "training_features_df = pd.concat([training_features_df, X_tar_train], axis=1)\n",
    "testing_features_df = pd.concat([testing_features_df, X_tar_test], axis=1)\n",
    "\n",
    "training_features_df = training_features_df.drop(target_encoder_columns, axis=1)\n",
    "testing_features_df = testing_features_df.drop(target_encoder_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06e93475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final column list\n",
    "all_columns = final_target_encoded_cols + numeric_cols + list(ohe_after_cols) + ordinal_columns + pca_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69adeac",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6911ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate MI Scores\n",
    "\n",
    "scores = make_mi_scores(X_train[all_columns], y_train.status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bd3f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = []\n",
    "for inx in list(scores.index):\n",
    "#     print(inx, scores.at[inx])\n",
    "    if(scores.at[inx] > 0.0001):\n",
    "        selected_columns.append(inx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b188313",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47c2fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=1300,\n",
    "                                  random_state=42,\n",
    "                                  max_features='auto', \n",
    "                                  max_depth=60, \n",
    "                                  min_samples_split=6,\n",
    "                                  min_samples_leaf=3,\n",
    "                                  bootstrap=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b5c6cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=60, min_samples_leaf=3,\n",
       "                       min_samples_split=6, n_estimators=1300, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_model.fit(X_train[selected_columns], y_train.status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45be77ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8127384960718294"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction \n",
    "predic = rf_model.predict(X_test[selected_columns]).transpose()\n",
    "accuracy_score(y_test.status_group, predic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ac1de",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7f96bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = make_mi_scores(training_features_df[all_columns], training_features_df.status_group)\n",
    "\n",
    "final_columns = []\n",
    "for inx in list(mi_scores.index):\n",
    "#     print(inx, mi_scores.at[inx])\n",
    "    if(mi_scores.at[inx] > 0.0006):\n",
    "        final_columns.append(inx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0caffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model training\n",
    "\n",
    "# rf_model.fit(training_features_df[final_columns], training_features_df['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03143c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = rf_model.predict(testing_features_df[final_columns]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16308c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# status_group_re_mappings = {1: 'functional', 2 : 'non functional', 3: 'functional needs repair'}\n",
    "# output = pd.DataFrame({'id': testing_features_df.index, 'status_group': prediction })\n",
    "# output['status_group'] = output.status_group.map(status_group_re_mappings)\n",
    "# output.to_csv('final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6d3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebfb67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
